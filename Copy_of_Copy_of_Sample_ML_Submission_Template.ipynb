{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "H0kj-8xxnORC",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "578E2V7j08f6",
        "qBMux9mC6MCf",
        "rAdphbQ9Bhjc",
        "yiiVWRdJDDil",
        "T5CmagL3EC8N",
        "qjKvONjwE8ra",
        "TIqpNgepFxVj",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahulverma2045/NETFLIX-_MOVIES_AND_TV_SHOWS_CLUSTRING/blob/main/Copy_of_Copy_of_Sample_ML_Submission_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - NETFLIX_MOVIES_AND_TV_SHOWS_CLUSTERING\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Type**    - Unsupervised\n",
        "# **Contribution**    - Team\n",
        "# **Team Member 1 -**RAHUL VERMA\n",
        "# **Team Member 2 -**SUMIT SHARMA\n",
        "# **Team Member 3 -**KHUSHBOO KHANRAH\n",
        "# **Team Member 4 -**VISHAL TOMAR"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "#In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "#Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings.\n",
        "\n",
        "# *In this project, you are required to do\n",
        "\n",
        "\n",
        "\n",
        "#Exploratory Data Analysis\n",
        "\n",
        "#Understanding what type content is available in different countries\n",
        "\n",
        "#Is Netflix has increasingly focusing on TV rather than movies in recent years.\n",
        "\n",
        "# Clustering similar content by matching text-based features"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attribute Information**\n",
        "\n",
        "\n",
        "#show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "#type : Identifier - A Movie or TV Show\n",
        "\n",
        "#title : Title of the Movie / Tv Show\n",
        "\n",
        "#director : Director of the Movie\n",
        "\n",
        "#cast : Actors involved in the movie / show\n",
        "\n",
        "#country : Country where the movie / show was produced\n",
        "\n",
        "#date_added : Date it was added on Netflix\n",
        "\n",
        "#release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "#rating : TV Rating of the movie / show\n",
        "\n",
        "#duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "#listed_in : Genere\n",
        "\n",
        "#description: The Summary description"
      ],
      "metadata": {
        "id": "rlfd3n2OfjSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# importing important libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "from sklearn.preprocessing import StandardScaler,normalize\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords  #stopwords\n",
        "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
        "from nltk.stem import PorterStemmer,LancasterStemmer  \n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
        "import nltk \n",
        "\n",
        "\n",
        "# libraries used to implement clusters\n",
        "from sklearn.metrics import silhouette_score\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "from sklearn.metrics import silhouette_samples\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from scipy.cluster.hierarchy import linkage\n",
        "\n",
        "# Library of warnings would assist in ignoring warnings issued\n",
        "import warnings;warnings.filterwarnings('ignore')\n",
        "import warnings;warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df =  pd.read_csv('/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# head of the data\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tail of the dataset\n",
        "df.tail()\n",
        "     "
      ],
      "metadata": {
        "id": "TYL30BlyiIXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset  basic Info about data\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# describing the dataset\n",
        "df.describe(include = ['category', 'object']).transpose()"
      ],
      "metadata": {
        "id": "ogz1074YicM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Droping the show_id column\n",
        "df = df.drop(['show_id'], axis =1)"
      ],
      "metadata": {
        "id": "jZTXj-gJFiy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# checking missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize = (10,8), facecolor = 'y')\n",
        "ax = plt.gca()\n",
        "sns.heatmap(df.isnull(), cmap = 'Blues_r', ax =ax,  linecolor = 'r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling the missing values in director, cast and country column\n",
        "df['director'] =df.director.fillna('None')\n",
        "df['cast'] =  df['cast'].fillna('not available')\n",
        "df['country'] = df['country'].fillna('missing')\n",
        "     "
      ],
      "metadata": {
        "id": "ipoOspTUq_On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# checking for the missing values after imputing values in above columns\n",
        "df.isnull().sum()\n",
        "     "
      ],
      "metadata": {
        "id": "EV3QSE-ZrEwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date_added']"
      ],
      "metadata": {
        "id": "iInaH8_UGmlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(axis = 0, inplace = True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "E4JmQlV5s_sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# checking the null values after removal\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "jGsDXLQBrJqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping date_added and rating rows where values are missing\n",
        "df = df.dropna(axis =0, subset = ['date_added', 'rating'] )\n",
        "df['date_added'].isnull().sum()"
      ],
      "metadata": {
        "id": "M_oFZbqjD_Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns\n",
        "     "
      ],
      "metadata": {
        "id": "k7terY1Hx-0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "# type : Identifier - A Movie or TV Show\n",
        "\n",
        "# title : Title of the Movie / Tv Show\n",
        "\n",
        "# director : Director of the Movie\n",
        "\n",
        "# cast : Actors involved in the movie / show\n",
        "\n",
        "# country : Country where the movie / show was produced\n",
        "\n",
        "# date_added : Date it was added on Netflix\n",
        "\n",
        "# release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "# rating : TV Rating of the movie / show\n",
        "\n",
        "# duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "# listed_in : Genere\n",
        "\n",
        "# description : The Summary description"
      ],
      "metadata": {
        "id": "1JPt2ah7yMhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df.columns.tolist():\n",
        "  print(\"No. of unique values in\",i,\"is\",df[i].nunique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summing null values\n",
        "print('Missing Data Count')\n",
        "df.isna().sum()[df.isna().sum() > 0].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "WcMrykUdH-aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Missing Data Percentage')\n",
        "print(round(df.isna().sum()[df.isna().sum() > 0].sort_values(ascending=False)/len(df)*100,2))"
      ],
      "metadata": {
        "id": "4zJ39yRqIFBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['director']] = df[['director']].fillna('Unknown')\n",
        "df[['cast']]     = df[['cast']].fillna('Unknown')\n",
        "df[['country'] ] = df[['country']].fillna('Unknown')"
      ],
      "metadata": {
        "id": "Zee914sGIIUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['date_added'], inplace=True)"
      ],
      "metadata": {
        "id": "U-9YqdU5Hqi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "2tGJvt9fIMEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['rating'].fillna(value=df['rating'].mode()[0],inplace=True)"
      ],
      "metadata": {
        "id": "DFs6mSf1IpmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "xYgupFyKIvNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['country'] = df['country'].apply(lambda x: x.split(',')[0])\n",
        "df['listed_in'] = df['listed_in'].apply(lambda x: x.split(',')[0])"
      ],
      "metadata": {
        "id": "KEiSSohPI6Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns and data types\")\n",
        "pd.DataFrame(df.dtypes).rename(columns = {0:'dtype'})"
      ],
      "metadata": {
        "id": "bssgsZBHJBAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert timestamp to datetime format to fetch the other details\n",
        "df[\"date_added\"] = pd.to_datetime(df['date_added'])"
      ],
      "metadata": {
        "id": "Xney4IE0Kz6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#addding new column to dataframe such as 'month_added'and 'year_added' to gain more insights from the data \n",
        "df['year_added'] = df['date_added'].dt.year\n",
        "df['month_added'] = df['date_added'].dt.month\n",
        "     "
      ],
      "metadata": {
        "id": "S7F56Z0ILPir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to get the year addedfrom the date_added\n",
        "def func_1(x):\n",
        "  return x.split()[0]"
      ],
      "metadata": {
        "id": "HP7OPYMuDu0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to extract the month from a date string\n",
        "def func_1(date_str):\n",
        "    try:\n",
        "        return datetime.strptime(date_str, '%B %d, %Y').month\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Apply the function to the 'date_added' column to get the month added column\n",
        "df['month_added'] = df['date_added'].apply(func_1)\n",
        "\n",
        "# Extract the year from the 'date_added' column to get the year added column\n",
        "df['year_added'] = df['date_added'].apply(lambda x: x.split()[-1] if isinstance(x, str) else None)\n",
        "\n",
        "# Convert the release year column to a string\n",
        "df['release_year'] = df['release_year'].astype(str)\n",
        "\n",
        "# Drop the original 'date_added' column\n",
        "df = df.drop('date_added', axis=1)\n"
      ],
      "metadata": {
        "id": "RUjvkgl_FDL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the head of the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rjvdgd8NDxgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining two sub-datasets based on type of the content\n",
        "shows_df = df[df['type'] == 'TV Show']\n",
        "movie_df  = df[df['type']== 'Movie']\n"
      ],
      "metadata": {
        "id": "F-ec2MYIHV-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a column n movie_df dataframe using func_1 funtion\n",
        "movie_df['duration'] = movie_df['duration'].apply(func_1)"
      ],
      "metadata": {
        "id": "okCfLmfaHYmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# head of movie_data\n",
        "movie_df.head()"
      ],
      "metadata": {
        "id": "B3J-sWqsHbjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Type distribution**"
      ],
      "metadata": {
        "id": "BQRmh6zwCz1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# plotting the type distribution\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "df['type'].value_counts().plot.pie(autopct=\"%1.1f%%\", cmap = 'Paired', shadow=True, startangle=190,explode=(0.04,0.04));\n",
        "plt.title('Distribution of content Type')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting top 15 countries based on content type\n",
        "\n",
        "\n",
        "# creating a  TV shows dataset where imputed values are not taking into account\n",
        "tv_shows_df = df[df['type'] == 'TV Show']\n",
        "tv_shows_df = tv_shows_df[tv_shows_df['country'] != 'missing']\n",
        "\n",
        "# creating a  movies dataset where imputed values are not taking into account\n",
        "movies_df  = df[df['type']== 'Movie']\n",
        "movies_df = movies_df[movies_df['country'] != 'missing']\n",
        "\n",
        "\n",
        "# getting unique values shows dataframe\n",
        "country_df_shows = pd.DataFrame(tv_shows_df['country'].str.split(', ', expand= True).stack().reset_index(level =1, drop = True).value_counts()).reset_index()\n",
        "country_df_shows.rename(columns = {'index': 'country', 0:'shows counts'}, inplace =True)\n",
        "top_15_countries = country_df_shows.head(15)\n",
        "\n",
        "# getting unique values shows dataframe fir movies\n",
        "country_df_movies = pd.DataFrame(movies_df['country'].str.split(', ', expand= True).stack().reset_index(level =1, drop = True).value_counts()).reset_index()\n",
        "country_df_movies.rename(columns = {'index': 'country', 0:'movies counts'}, inplace =True)\n",
        "top_15_countries_movies = country_df_movies.head(15)\n",
        "new_df = pd.concat([top_15_countries, top_15_countries_movies] , axis =1)\n",
        "\n",
        "# final dataframe\n",
        "new_df\n"
      ],
      "metadata": {
        "id": "BpUQd2VGCxA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 10 directors who have directed most move\n",
        "director_df  =  df[df['director'] != 'None']\n",
        "director_df = pd.DataFrame(director_df['director'].value_counts().head(10)).reset_index()\n",
        "director_df.rename(columns = {'index' : 'director', 'director' : 'counts'}, inplace= True)\n",
        "director_df\n",
        "\n"
      ],
      "metadata": {
        "id": "q0W0wvthDHaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Seasons**"
      ],
      "metadata": {
        "id": "r9BGZv5zDNuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# plotting seasons distribution for TV shows\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "\n",
        "\n",
        "seasons_df = pd.DataFrame(shows_df['duration'].value_counts()).reset_index()\n",
        "seasons_df.rename(columns = {'index': 'seasons', 'duration': 'counts'}, inplace = True)\n",
        "sns.barplot(data =seasons_df, x= 'seasons', y= 'counts')\n",
        "plt.xticks(rotation = 60)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "seasons_df"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Duration: ⌛**\n"
      ],
      "metadata": {
        "id": "IEQHBjCKI6S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# Create subsets for tv shows and movies.\n",
        "tv_shows = df[df['type'] == 'TV Show']\n",
        "movies = df[df['type'] == 'Movie']\n",
        "\n",
        "# Select the durations for both.\n",
        "duration_tv_shows = tv_shows['duration'].reset_index()\n",
        "duration_movies = movies['duration'].reset_index()\n",
        "\n",
        "# Remove string values from tv shows duration.\n",
        "duration_tv_shows.duration = duration_tv_shows.duration.str.replace(' Season', '') \\\n",
        "                                                       .str.replace(' Seasons', '') \\\n",
        "                                                       .str.replace('s', '')                                                       \n",
        "duration_tv_shows.duration = duration_tv_shows.duration.astype(str).astype(int)\n",
        "\n",
        "# Remove string values from movie duration.\n",
        "duration_movies.duration = duration_movies.duration.str.replace(' min', '')                                                       \n",
        "duration_movies.duration = duration_movies.duration.astype(str).astype(int)"
      ],
      "metadata": {
        "id": "3A9hrKepZuLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the above durations.\n",
        "plt.figure(figsize=(8,4), dpi=120)\n",
        "sns.set(style=\"darkgrid\")\n",
        "sns.histplot(data=duration_tv_shows['duration'], color='#db0000')\n",
        "plt.title('Duration of Tv Shows.')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-iAT4UEfZ9Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(8,4), dpi=120)\n",
        "sns.set(style=\"darkgrid\")\n",
        "sns.histplot(data=duration_movies['duration'], color='#db0000')\n",
        "plt.title('Duration of movies')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mtQoJerraFH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rating: ⭐⭐⭐**"
      ],
      "metadata": {
        "id": "MvZ8qYQDI9-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# visualizing the distribution of various ratings\n",
        "order =  ['G', 'TV-Y', 'TV-G', 'PG', 'TV-Y7', 'TV-Y7-FV', 'TV-PG', 'PG-13', 'TV-14', 'R', 'NC-17', 'TV-MA']\n",
        "plt.figure(figsize=(15,7))\n",
        "g = sns.countplot(df.rating, hue=df.type, order=order, palette='Set2_r');\n",
        "plt.title(\"Ratings for Movies & TV Shows\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Total Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding top 20 movie genres in movies and TV shows\n",
        "genres_shows = shows_df.listed_in.str.split(', ', expand=True).stack().reset_index(level=1, drop=True)\n",
        "genres_movies = movie_df.listed_in.str.split(', ', expand=True).stack().reset_index(level=1, drop=True)\n",
        "\n",
        "\n",
        "fig , axes = plt.subplots(1,2, figsize = (15,8))\n",
        "\n",
        "sns.countplot(y = genres_shows, order=genres_shows.value_counts().index[:20], ax= axes[0])\n",
        "sns.countplot(y = genres_movies, order=genres_movies.value_counts().index[:20], ax= axes[1])\n",
        "\n",
        "axes[0].set_xlabel('count', fontsize = 15, c='b')\n",
        "axes[1].set_xlabel('count', fontsize = 15, c='b')\n",
        "axes[0].set_ylabel('genres', fontsize = 20, c = 'b')\n",
        "axes[0].set_title('Top 20 shows genres', fontsize = 15)\n",
        "axes[1].set_title('Top 20 movie genres', fontsize = 15 )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(7,9))\n",
        "# g = sns.countplot(y = genres_shows, order=genres_shows.value_counts().index[:20])\n",
        "\n",
        "# plt.xlabel('Titles')\n",
        "plt.ylabel('Genres')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_nqaicYJJmST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Actors**"
      ],
      "metadata": {
        "id": "yilU3_w0LRSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# finding the top actors who worked in most content in movies and TV shows\n",
        "tv_shows_df = df[df['type'] == 'TV Show']\n",
        "tv_shows_actors = tv_shows_df[tv_shows_df['cast'] != 'not available']\n",
        "\n",
        "movies_df  = df[df['type']== 'Movie']\n",
        "movie_actors = movies_df[movies_df['cast'] != 'not available']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "top_shows_actors =  tv_shows_actors.cast.str.split(',', expand= True).stack().reset_index(level =1, drop = True)\n",
        "top_movie_actors =  movie_actors.cast.str.split(',', expand= True).stack().reset_index(level =1, drop = True)\n",
        "\n",
        "\n",
        "\n",
        "fig , axes = plt.subplots(1,2, figsize = (15,8))\n",
        "\n",
        "sns.countplot(y = top_shows_actors, order=top_shows_actors.value_counts().index[:15], ax= axes[0], palette ='cividis_r')\n",
        "sns.countplot(y = top_movie_actors, order=top_movie_actors.value_counts().index[:15], ax= axes[1], palette = 'cividis_r')\n",
        "\n",
        "axes[0].set_xlabel('count', fontsize = 15, c='black')\n",
        "axes[1].set_xlabel('count', fontsize = 15, c='black')\n",
        "axes[0].set_ylabel('Actors', fontsize = 20, c = 'black')\n",
        "axes[0].set_title('Top 15 shows actors', fontsize = 15)\n",
        "axes[1].set_title('Top 15 movie actors', fontsize = 15 )\n",
        "\n",
        "plt.ylabel('Actors')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Most used word in title of content on Netflix**"
      ],
      "metadata": {
        "id": "HqCCShAGLnVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the wordcloud\n",
        "from wordcloud import WordCloud,ImageColorGenerator"
      ],
      "metadata": {
        "id": "El7705kVx22Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "#chcking word cloud from title column\n",
        "text = \" \".join(topic for topic in df.title.astype(str))\n",
        "print (\"There are {} words in the combination of all titles.\".format(len(text)))\n",
        "\n",
        "# Create and generate a word cloud image:\n",
        "wordcloud = WordCloud(background_color=\"black\", width=800, height=400).generate(text)\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.rcParams[\"figure.figsize\"] = (14,6)\n",
        "plt.tight_layout(pad=0)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j0ombXsnx6P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cast: 🎭**"
      ],
      "metadata": {
        "id": "CUuEJyjPWvrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "df['cast_name'] = df['cast'].apply(lambda x :  x.split(',')) \n",
        "cast_count = []\n",
        "for i in df['cast_name']: cast_count += i\n",
        "    \n",
        "cast_dict = dict((i, cast_count.count(i)) for i in cast_count)\n",
        "\n",
        "df_cast_count = pd.DataFrame(cast_dict.values(),cast_dict.keys()).reset_index().sort_values(0,ascending=False).rename(\n",
        "    columns = {'index' : 'cast_name', 0 : 'count'}).iloc[1:21]\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.barplot(x='cast_name',y='count',data=df_cast_count,palette=\"Dark2_r\")\n",
        "plt.title(\"Top-20 ACTORS on Netflix\",size='16',fontweight=\"bold\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Director: 🤠**"
      ],
      "metadata": {
        "id": "uPoFO-jUavh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['director']=='Unknown') & (df['type']=='Movie')].director.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 movie directors')"
      ],
      "metadata": {
        "id": "hjcM2zwGsMQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 TV show directors\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['director']=='Unknown') & (df['type']=='TV Show')].director.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 TV show directors')"
      ],
      "metadata": {
        "id": "Wca24Jm_sEo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Release_year : Actual Releaseyear of the movie / show**\n"
      ],
      "metadata": {
        "id": "GPj41YK_dI4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "sns.countplot(x=\"release_year\", data=df)\n",
        "plt.title(\"Number of movie/show relesed on year\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation =90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KzHvqraydYLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **country : Country where the movie / show was produced**"
      ],
      "metadata": {
        "id": "-JV9i2ZXe115"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "\n",
        "#top 15 country where the movie/shows was produced\n",
        "df[\"country\"].value_counts()[:15].sort_values(ascending=False).plot(kind=\"bar\")\n",
        "plt.title(\"Top 15 Country where the movie / show was produced\")\n",
        "plt.xlabel(\"Country\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7cGCS55-gSH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **listed_in : Genere**"
      ],
      "metadata": {
        "id": "ImmyQfoPfPUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# TOP 10 GENRES\n",
        "plt.figure(figsize=(10,5))\n",
        "df.listed_in.value_counts().nlargest(10).plot(kind='barh', color= 'crimson')\n",
        "plt.title('Top 10 genres', fontweight = 'bold')\n",
        "#sns.countplot(palette = 'cubehelix')"
      ],
      "metadata": {
        "id": "JdCktyg4trLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHARE TOP 3 GENRES\n",
        "df.listed_in.value_counts().nlargest(3).sum()/len(df)*100"
      ],
      "metadata": {
        "id": "DShnDxETt7Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHARE TOP 10 GENRES\n",
        "df.listed_in.value_counts().nlargest(10).sum()/len(df)*100"
      ],
      "metadata": {
        "id": "HR8iAl4St_b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dramas is the most popular genre followed by comedies and documentaries.\n",
        "\n",
        "These three genres account for about 12% of all movies and TV shows.\n",
        "\n",
        "This value increases to about 29% for top 10 genres."
      ],
      "metadata": {
        "id": "2jdJLAGOuHIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Hypothesis Testing**"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing.\n",
        "# **Hypothesis 1: The difference in the average duration of movies and TV shows on Netflix.**\n",
        "\n",
        "# **Hypothesis 2: Difference in the average number of seasons for TV shows on Netflix between those produced in the United States and those produced outside of the United States.**\n",
        "\n",
        "# **Hypothesis 3: The number of TV shows added to Netflix has increased over time.**"
      ],
      "metadata": {
        "id": "qXxf1SANyL2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypothetical Statement - 1) The difference in the average duration of movies and TV shows on Netflix.\n",
        "# 1. State Your research hypothesis as a null hypothesis and alternate hypothesis.\n",
        "# Null Hypothesis(H0) - There is no significant difference in the average duration of movies and TV shows on Netflix.\n",
        "\n",
        "# Alternative Hypothesis(H1) - There is a significant difference in the average duration of movies and TV shows on Netflix."
      ],
      "metadata": {
        "id": "oEokgQzCywYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Perform an appropriate statistical test.**"
      ],
      "metadata": {
        "id": "5WfbLj9qzieD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n"
      ],
      "metadata": {
        "id": "RQROIjvEy-HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Extract the durations of movies and TV shows from the dataset\n",
        "movie_durations = df[df['type'] == 'Movie']['duration']\n",
        "tv_show_durations = df[df['type'] == 'TV Show']['duration']\n",
        "\n",
        "# Perform two-sample t-test\n",
        "stat, p = ttest_ind(movie_durations, tv_show_durations, equal_var=False)\n",
        "\n",
        "# Print the test statistic and p-value\n",
        "print(\"Two-sample t-test statistic:\", stat)\n",
        "print(\"p-value:\", p)\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print(\"Failed to reject null hypothesis.\")\n",
        "else:\n",
        "    print(\"Reject null hypothesis.\")"
      ],
      "metadata": {
        "id": "arZnx7m_zBtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## There is a significant difference in the average duration of movies and TV shows on Netflix.\n"
      ],
      "metadata": {
        "id": "kB1fe92gzFjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which statistical test have you done to obtain P-Value?\n",
        "# The statistical test used to obtain the p-value is the two-sample t-test. This test was chosen because we are comparing the means of two independent samples (movie durations and TV show durations), and we want to determine whether the difference between the sample means is statistically significant or could have occurred by chance.\n",
        "\n",
        "# Why did you choose the specific statistical test?\n",
        "# The two-sample t-test assumes that the samples are normally distributed, the variances of the two samples are not equal, and the samples are independent. In this case, we assumed that the duration of movies and TV shows on Netflix are normally distributed, and that the two samples are independent. The assumption of unequal variances was also made because the variance of movie durations and TV show durations may be different due to the nature of the content"
      ],
      "metadata": {
        "id": "Qi8kBHTFzJHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hypothetical Statement - 2) Difference in the average number of seasons for TV shows on Netflix between those produced in the United States and those produced outside of the United States.**"
      ],
      "metadata": {
        "id": "TcrWkGc3zRUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. State Your research hypothesis as a null hypothesis and alternate hypothesis.\n",
        "# Null hypothesis : There is no significant difference in the average number of seasons for TV shows on Netflix between those produced in the United States and those produced outside of the United States.\n",
        "\n",
        "# Alternate hypothesis : There is a significant difference in the average number of seasons for TV shows on Netflix between those produced in the United States and those produced outside of the United States."
      ],
      "metadata": {
        "id": "hLP1nzV-zZOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Perform an appropriate statistical test.**"
      ],
      "metadata": {
        "id": "dmQ9wHpuzf8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n"
      ],
      "metadata": {
        "id": "qJnE6QrrzoNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Extract the number of seasons for TV shows produced in the US and outside the US\n",
        "# Extract the number of seasons for TV shows produced in the US and outside the US\n",
        "us_shows = df[(df['type'] == 'TV Show') & (df['country'] == 'United States')]\n",
        "us_shows_seasons = us_shows['duration'].apply(lambda x: int(x.split(' ')[0]) if isinstance(x, str) and 'season' in x else 0)\n",
        "\n",
        "non_us_shows = df[(df['type'] == 'TV Show') & (df['country'] != 'United States')]\n",
        "non_us_shows_seasons = non_us_shows['duration'].apply(lambda x: int(x.split(' ')[0]) if isinstance(x, str) and 'season' in x else 0)\n",
        "\n",
        "# Perform two-sample t-test\n",
        "stat, p = ttest_ind(us_shows_seasons, non_us_shows_seasons, equal_var=False)\n",
        "\n",
        "# Print the test statistic and p-value\n",
        "print(\"Two-sample t-test statistic:\", stat)\n",
        "print(\"p-value:\", p)\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print(\"Failed to reject null hypothesis.\")\n",
        "else:\n",
        "    print(\"Reject null hypothesis.\")\n"
      ],
      "metadata": {
        "id": "r8YT8SM_zq8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  There is a significant difference in the average number of seasons for TV shows on Netflix\n",
        "#  between those produced in the United States and those produced outside of the United States."
      ],
      "metadata": {
        "id": "jPHgk3tHz14J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which statistical test have you done to obtain P-Value?\n",
        "# The statistical test used here is a two-sample t-test. This test is used to compare the means of two independent samples and determine if they are statistically different from each other.\n",
        "\n",
        "# Why did you choose the specific statistical test?\n",
        "# In this case, we are comparing the number of seasons of TV shows produced in the US and outside the US. We chose this test because we want to determine if there is a statistically significant difference in the mean number of seasons between the two groups. We also assumed that the variances of the two groups are not equal, so we set the equal_var parameter to False when calling the ttest_ind() function."
      ],
      "metadata": {
        "id": "R-XDNKaJz4ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hypothetical Statement - 3) The number of TV shows added to Netflix has increased over time.**\n",
        "# **1. State Your research hypothesis as a null hypothesis and alternate hypothesis.**\n",
        "# Null hypothesis: The mean number of TV shows added to Netflix per year has not changed over time.\n",
        "\n",
        "# Alternative hypothesis: The mean number of TV shows added to Netflix per year has increased over time."
      ],
      "metadata": {
        "id": "1WyxOsKo05QZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Perform an appropriate statistical test.**"
      ],
      "metadata": {
        "id": "zfO80ksN0KzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n"
      ],
      "metadata": {
        "id": "5h4Mvb6R0N0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Extract the year from the date_added column\n",
        "df['year_added'] = pd.DatetimeIndex(df['date_added']).year\n",
        "\n",
        "# Extract the number of TV shows added to Netflix each year\n",
        "tv_shows = df[df['type'] == 'TV Show']\n",
        "tv_shows_by_year = tv_shows.groupby('year_added').size()\n",
        "\n",
        "# Perform a linear regression to test for a positive slope (i.e., an increase over time)\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(tv_shows_by_year.index, tv_shows_by_year)\n",
        "\n",
        "# Print the p-value\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value > alpha:\n",
        "    print(\"Failed to reject null hypothesis.\")\n",
        "else:\n",
        "    print(\"Reject null hypothesis.\")"
      ],
      "metadata": {
        "id": "SLZJSnfZ0Sm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# It means the mean number of TV shows added to Netflix per year has not changed over time.\n"
      ],
      "metadata": {
        "id": "o2e5grEa0VVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which statistical test have you done to obtain P-Value?\n",
        "# In this code, a linear regression is performed using the stats.linregress function from the scipy module. The purpose of the regression is to test for a positive slope (i.e., an increase over time) in the number of TV shows added to Netflix each year. The p-value is then calculated based on the results of the regression.\n",
        "\n",
        "# A p-value is a measure of the evidence against the null hypothesis. In this case, the null hypothesis is that the number of TV shows added to Netflix has not increased over time (i.e., the slope is zero). The alternative hypothesis is that the number of TV shows added to Netflix has increased over time (i.e., the slope is positive).\n",
        "\n",
        "# Why did you choose the specific statistical test?\n",
        "# The specific statistical test used in this code is a linear regression with a hypothesis test on the slope coefficient. This is appropriate because we are interested in testing for a trend over time, and a linear regression allows us to model the relationship between the year and the number of TV shows added to Netflix. The p-value calculated from the regression provides evidence for or against the alternative hypothesis that there is a positive trend.\n",
        "\n"
      ],
      "metadata": {
        "id": "Hb2UxsvF0Z8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Missing Values/Null Values Count\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# plotting graph\n",
        "fig,ax = plt.subplots(1,2, figsize=(15,5))\n",
        "\n",
        "# Display boxplot and dist plot.\n",
        "sns.distplot(x=df['release_year'], ax=ax[0])\n",
        "sns.boxplot(data=df, ax=ax[1])\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.NOT NEEDED"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "df['organized'] =(df['description'].astype(str) + ' ' + \n",
        "                  df['listed_in'].astype(str)   + ' ' + \n",
        "                  df['rating'].astype(str)      + ' ' + \n",
        "                  df['cast'].astype(str)        + ' ' + \n",
        "                  df['country'].astype(str)     + ' ' + \n",
        "                  df['director'].astype(str))"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.organized[0]\n"
      ],
      "metadata": {
        "id": "lj0V6ogQKbPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "df['Lower_casing']= df['organized'].str.lower()\n",
        "     "
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Lower_casing[0]\n"
      ],
      "metadata": {
        "id": "eYGgbyOkKzS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "[punc for punc in string.punctuation]"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "    # remove punctuation from text\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))"
      ],
      "metadata": {
        "id": "Fb5cP4riWfNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_text'] = df['Lower_casing'].apply(remove_punctuation)\n"
      ],
      "metadata": {
        "id": "I55wTWYQWi-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.cleaned_text[0]\n"
      ],
      "metadata": {
        "id": "XboALPE2Wohz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "vNHZEY8iW_Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaned(x):\n",
        "    return re.sub(r\"[^a-zA-Z ]\", \"\", str(x))\n",
        "\n",
        "def remove_urls(text):\n",
        "    cleaned_text = re.sub(r'http\\S+', '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_digits(text):\n",
        "    cleaned_text = re.sub(r'\\w*\\d\\w*', '', text)\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "zQi21ZxGXDAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['removed_words']  = df['cleaned_text'].apply(cleaned)\n",
        "df['removed_url']    = df['removed_words'].apply(remove_urls)\n",
        "df['removed_digits'] = df['removed_url'].apply(remove_digits)\n",
        "     "
      ],
      "metadata": {
        "id": "V2CLle3BXHdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "     "
      ],
      "metadata": {
        "id": "UG-s-3RhWGK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    cleaned_text = ' '.join(words)\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['removed_stopwords'] = df['removed_digits'].apply(remove_stopwords)\n",
        "df.removed_stopwords[0]"
      ],
      "metadata": {
        "id": "3aza2d5XWNSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "def remove_whitespaces(text):\n",
        "    cleaned_text = text.strip()\n",
        "    return cleaned_text\n",
        "     \n"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  df['removed_whitespaces']=df['removed_stopwords'].apply(remove_whitespaces)\n",
        "df['removed_whitespaces'].head()"
      ],
      "metadata": {
        "id": "egF3M1dbXUNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text\n",
        "#!pip install rephrase\n"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from rephrase import Rephraser"
      ],
      "metadata": {
        "id": "1wKOBd9VXdJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "# Tokenization\n",
        "def tokenize_text(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenized'] = df['removed_whitespaces'].apply(tokenize_text)\n"
      ],
      "metadata": {
        "id": "rbLuR3vqV-Ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenized'].head()"
      ],
      "metadata": {
        "id": "Li46AJ_lXjwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "     "
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "def normalize_text(tokens):\n",
        "    stemmer = SnowballStemmer('english')          # apply stemming to tokens\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "    lemmatizer = WordNetLemmatizer()              # apply lemmatization\n",
        "    normalized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
        "    normalized_text = ' '.join(normalized_tokens) # join normalized tokens \n",
        "    return normalized_text"
      ],
      "metadata": {
        "id": "Gp-aUS2dVttD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['normalized'] = df['tokenized'].apply(normalize_text)\n"
      ],
      "metadata": {
        "id": "0_m_rreDVyjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['normalized'].head()"
      ],
      "metadata": {
        "id": "FeR3roUeXpSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "     \n",
        "\n",
        "#def pos_tagging(text):\n",
        "#    tagged_tokens = nltk.pos_tag(text) # perform POS tagging on tokens\n",
        "#    return tagged_tokens                 # return list of (word, POS tag) tuples\n",
        "     \n",
        "\n",
        "#df['tagged'] = df['tokenized'].apply(lambda x: pos_tagging(x))\n",
        "#df['tagged'] = df['tagged'].apply(lambda x: [str(t) for t in x])"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "new_df = df[['title', 'normalized']]\n",
        "new_df.head()\n"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using tfidf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "     \n",
        "t_vectorizer = TfidfVectorizer(max_features=20000)\n",
        "x= t_vectorizer.fit_transform(new_df['normalized'])\n",
        "\n",
        "x.shape"
      ],
      "metadata": {
        "id": "HwHLRMznX35F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOT NEEDED"
      ],
      "metadata": {
        "id": "2FWd9ZwWOkbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOT NEEDED"
      ],
      "metadata": {
        "id": "X0DfIO7nOo9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOT NEEDED"
      ],
      "metadata": {
        "id": "DOFf9jnNOsR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOT NEEDED"
      ],
      "metadata": {
        "id": "30eCS2N3Ou5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Answer Here.YES\n",
        " As the number of features (words in this case) is high, it is useful to apply dimensionality reduction to simplify the dataset and improve computational efficiency."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA()\n",
        "pca.fit(X.toarray())\n",
        "     "
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOT NEEDED"
      ],
      "metadata": {
        "id": "ksGYXQrsPYkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.NOT NEEDED"
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "\n",
        "def evaluate_clustering_model(model, X, y_predict):\n",
        "    \"\"\"\n",
        "    Evaluate a clustering model and print the results.\n",
        "    & Returns\n",
        "    Model evaluation result\n",
        "    \"\"\"\n",
        "    # Calculate the number of clusters and evaluation metrics\n",
        "    n_clusters = len(set(y_predict))\n",
        "    S_score = silhouette_score(X, y_predict)\n",
        "    CH_score = calinski_harabasz_score(X, y_predict)\n",
        "    DB_score = davies_bouldin_score(X, y_predict)\n",
        "    \n",
        "    # Print the evaluation results\n",
        "    print(f\"Number of clusters: {n_clusters}\")\n",
        "    print(f\"Silhouette score: {S_score:.4f}\")\n",
        "    print(f\"Calinski-Harabasz score: {CH_score:.4f}\")\n",
        "    print(f\"Davies-Bouldin score: {DB_score:.4f}\")\n",
        "    \n",
        "    # Create a dictionary to store the evaluation scores\n",
        "    scores_dict = {\"silhouette_score\": S_score,\n",
        "                   \"calinski_harabasz_score\": CH_score,\n",
        "                   \"davies_bouldin_score\": DB_score}\n",
        "    \n",
        "    # Create a dataframe to display the evaluation results\n",
        "    df_eval = pd.DataFrame({\"Evaluation Metric\": [\"Silhouette Score\", \n",
        "                                                  \"Calinski-Harabasz Score\", \n",
        "                                                  \"Davies-Bouldin Score\"],\n",
        "                                     \"Score\": [S_score, CH_score, DB_score]})\n",
        "    \n",
        "    # Print the dataframe\n",
        "    print(tabulate(df_eval, headers=\"keys\", tablefmt=\"grid\"))\n",
        "    \n",
        "    # Return the evaluation results\n",
        "    return {\"n_clusters\": n_clusters,\n",
        "            \"silhouette_score\": S_score,\n",
        "            \"calinski_harabasz_score\": CH_score,\n",
        "            \"davies_bouldin_score\": DB_score}\n",
        "\n",
        "def plot_clustering_scores(scores_dict):\n",
        "    \"\"\"\n",
        "    Plot the clustering evaluation scores using a bar chart.\n",
        "    \"\"\"\n",
        "    # Extract the scores from the dictionary\n",
        "    scores = [scores_dict[\"silhouette_score\"], scores_dict[\"calinski_harabasz_score\"], scores_dict[\"davies_bouldin_score\"]]\n",
        "    labels = [\"Silhouette\", \"Calinski-Harabasz\", \"Davies-Bouldin\"]\n",
        "    \n",
        "    # Plot the scores as a bar chart\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.bar(labels, scores, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n",
        "    \n",
        "    # Add labels and titles\n",
        "    ax.set_xlabel(\"Evaluation Metric\")\n",
        "    ax.set_ylabel(\"Score\")\n",
        "    ax.set_title(\"Clustering Evaluation Scores\")\n",
        "    \n",
        "    # Set the y-axis limits to the range of the scores\n",
        "    ax.set_ylim([np.min(scores) - 0.1, np.max(scores) + 0.1])\n",
        "    \n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "FC7KVJ28Pqgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Model - 1 K-Means Clustering**"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#finding optimal number of clusters using the elbow method  \n",
        "from sklearn.cluster import KMeans  \n",
        "wcss_list= []  #Initializing the list for the values of WCSS  \n",
        "  \n",
        "#Using for loop for iterations from 1 to 30.  \n",
        "for i in range(1, 30):  \n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state= 42)  \n",
        "    kmeans.fit(X)  \n",
        "    wcss_list.append(kmeans.inertia_)  \n",
        "plt.plot(range(1, 30), wcss_list)  \n",
        "plt.title('The Elobw Method Graph')  \n",
        "plt.xlabel('Number of clusters(k)')  \n",
        "plt.ylabel('wcss_list')  \n",
        "plt.show() "
      ],
      "metadata": {
        "id": "oVPHh3JsY8EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}